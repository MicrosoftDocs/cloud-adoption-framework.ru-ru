---
title: Надежные средства ИИ и ответственный подход к их использованию
description: Узнайте об шести принципах корпорации Майкрософт по обеспечению безопасности искусственного интеллекта, инклюзивности, надежности, безопасности, геометрии, прозрачности и конфиденциальности.
author: msteller-Ai
ms.author: brblanch
ms.date: 01/20/2021
ms.topic: conceptual
ms.service: cloud-adoption-framework
ms.subservice: innovate
ms.custom: think-tank
ms.openlocfilehash: 8fa6f164cea1a5382a2a6591052936cb18a76784
ms.sourcegitcommit: b8f8b7631aabaab28e9705934bf67dad15e3a179
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/03/2021
ms.locfileid: "101792760"
---
# <a name="responsible-and-trusted-ai"></a>Надежные средства ИИ и ответственный подход к их использованию

Корпорация Майкрософт расправила шесть ключевых принципов для ответственного AI: отчетность, инклюзивность, надежность и безопасность, равноправие, прозрачность, конфиденциальность и безопасность. Эти принципы необходимы для создания ответственного и надежного искусственного интеллекта при переходе на более распространенные продукты и службы. Они поясняются двумя перспективами: безупречность и объяснение.

![Схема ответственных принципов искусственного интеллекта.](./media/responsible-ai-principles.png)

## <a name="ethical"></a>Этического

С точки зрения безупречного решения AI должен быть справедливым и инклюзивным в своих утверждениях, быть разумным для принятия решений, а также не разграничить или мешать различным состязаниям, нарушениям или фону.

Корпорация Майкрософт установила безупречный Комитет по AI, этике и влиянию на проектирование и исследование [аесер](https://www.microsoft.com/ai/our-approach?activetab=pivot1%3aprimaryr5)в 2017. Основная обязанность комитетов заключается в том, чтобы порекомендовать ответственные проблемы, технологии, процессы и рекомендации. Дополнительные сведения о Аесер см. [в этом модуле Microsoft Learn](/learn/modules/microsoft-responsible-ai-practices/3-microsoft-governance-model).

### <a name="accountability"></a>Система отчетности

Учет — это важный основополагающий принцип ответственного ии. Пользователи, которые разрабатывает и развертывают систему AI, должны быть ответственными за ее действия и решения, особенно при продвижении к более автономным системам. Организациям следует рассмотреть возможность создания внутреннего текста проверки, который предоставляет сведения о разработке и развертывании ИСКУССТВЕНных систем, а также советы и рекомендации. Хотя это руководство может отличаться в зависимости от компании и региона, оно должно отражать ИСКУССТВЕНное путешествие Организации.

### <a name="inclusiveness"></a>Инклюзивность

Инклюзивность требует, чтобы в AI были рассмотрены все проблемы, возникающие и опыт работы с человеком, и включающие методики проектирования помогают разработчикам понять и устранить потенциальные барьеры, которые могут случайно исключить людей. Там, где это возможно, следует использовать технологию преобразования речи в текст, преобразования текста в речь и визуального распознавания, чтобы помочь людям с нарушениями слуха, визуального элемента и другими нарушениями.

### <a name="reliability-and-safety"></a>Надежность и защита

Для получения доверия системы AI должны быть надежными и безопасными. Важно, чтобы система выполнялась так, как она была изначально разработана, и для ее безопасного реагирования на новые ситуации. Его устойчивая устойчивость должна быть обусловлена намеренной или непреднамеренной манипуляцией. Жесткое тестирование и проверка должны быть установлены для операционных условий, чтобы система гарантированно отвечала на граничные варианты, а методы/B тестирования и заслуженный член/чалленжер должны быть интегрированы в процесс оценки.

Производительность системы на основе искусственного интеллекта может снизиться со временем, поэтому необходимо установить надежный процесс мониторинга и отслеживания модели, который должен быть установлен в активном состоянии и заранее оценивать производительность модели и при необходимости переучить ее, чтобы модернизировать ее.

## <a name="what-is-explainable"></a>Что можно объяснить

Объяснение помогает специалистам по обработке и анализу данных, аудиторам и руководителям, ответственным за принятие решений по обработке и обучению бизнес-процессов, обеспечить соответствие принятых решений и их выводы. Это также обеспечивает соответствие политикам компании, отраслевым стандартам и государственным нормам. Анализу данных должен иметь возможность объяснить заинтересованным лицам, как они достигают определенных уровней точности и что повлияло на этот результат. Аналогично, чтобы обеспечить соответствие политикам компании, аудитору требуется средство, проверяющее модель, а специалист по бизнес-решениям должен иметь возможность предоставить прозрачную модель для получения доверия.

### <a name="explainability-tools"></a>Средства для объяснения

Корпорация Майкрософт разработала [интерпретмл](https://interpret.ml/), набор средств с открытым исходным кодом, который помогает достичь объяснения модели и поддерживает модели с эффектами стекла и черными рамками.

- Модели с стеклянными рамками могут интерпретироваться из-за их структуры. Для этих моделей используйте пошаговый повышающий компьютер, который является состоянием алгоритма на основе дерева принятия решений или линейных моделей, предоставляет объяснения без потерь и может быть изменено экспертами домена.

- Модели с черными рамками более сложны для интерпретации из-за сложной внутренней структуры, нейронной сети. Такие пояснения, как ТРАВЯные или Шаплэйные пояснения (ШАП), преобразуют эти модели путем анализа связи между входом и выходом.

- [Фаирлеарн](https://fairlearn.org/) — это машинное обучение Azure интеграция и набор средств с открытым исходным кодом для пакета SDK и графического пользовательского интерфейса аутомл. Используйте пояснения, чтобы понять, что в основном влияет на специалистов по моделям и доменам для проверки этих влияния.

Изучите [интерпретируемость модели в машинное обучение Azure](/azure/machine-learning/how-to-machine-learning-interpretability) , чтобы получить дополнительные сведения о объяснении.

### <a name="fairness"></a>Справедливость

Равноправие является основным принципом этического характера, который все люди предназначены для понимания и применения. Этот принцип является еще более важным, когда разрабатываются системы ии. Ключевые проверки и балансы должны убедиться, что решения системы не разграничити пол, состязание, ориентацию сексуального характера или системам смещение к группе или отдельному лицу.

- Корпорация Майкрософт предоставляет [Контрольный список искусственного интеллекта](https://query.prod.cms.rt.microsoft.com/cms/api/am/binary/RE4t6dA) , который предлагает рекомендации и решения для AI-систем. Эти решения разбиваются на пять этапов: представление, прототип, сборка, запуск и развитие. На каждом этапе выводится список рекомендуемых действий по комплексной экспертизе, которые помогают максимально сократить влияние недостоверности в системе.

- Фаирлеарн интегрируется с Машинное обучение Azure и позволяет специалистам по обработке и анализу данных и разработчикам оценивать и улучшать равноправие своих систем ИИ. Панель элементов предоставляет различные алгоритмы защиты недостоверности и интерактивную панель мониторинга, которая визуализирует равноправие модели. Используйте набор средств и тщательно оцените равноправие модели во время ее построения. Это должно быть неотъемлемой частью процесса обработки и анализа данных.

Узнайте, как [устранить равноправие в моделях машинного обучения](/azure/machine-learning/concept-fairness-ml).

### <a name="transparency"></a>Прозрачность

Достижение прозрачности помогает команде понять данные и алгоритмы, используемые для обучения модели, применяемую логику преобразования к данным, созданную окончательную модель и связанные с ней активы. Эта информация предоставляет аналитические сведения о создании модели, что позволяет воспроизводить ее в прозрачном виде. Моментальные снимки в [рабочих областях машинное обучение Azure](/azure/machine-learning/concept-workspace) поддерживают прозрачность за счет записи или переобучения всех связанных с обучением активов и метрик, участвующих в эксперименте.

### <a name="privacy-and-security"></a>Конфиденциальность и безопасность

Владелец данных обязан защищать данные в системе AI, а конфиденциальность и безопасность являются неотъемлемой частью этой системы. Личная защита должна быть защищена, и доступ к ней должен осуществляться так, чтобы не нарушать конфиденциальность отдельных пользователей. [Разностное конфиденциальность Azure](/azure/machine-learning/concept-differential-privacy) защищает и сохраняет конфиденциальность, предохраняет данные и добавляя шум, чтобы скрыть персональные данные от специалистов по обработке и анализу данных.

## <a name="human-ai-guidelines"></a>Рекомендации по использованию для человеческого AI

Рекомендации по проектированию для человеческого искусственного интеллекта состоят из 18 принципов, которые происходят в течение четырех периодов: изначально, во время взаимодействия, при неправильной работе и со временем. Эти принципы предназначены для создания более включающей и ориентированной на человека системы AI.

### <a name="initially"></a>Изначально

- **Выясните, что может сделать система.** Если в системе AI используются или создаются метрики, важно отобразить их все и способ их трассировки.

- **Пояснить, насколько хорошо система может сделать то, что может сделать.** Помогите пользователям понять, что AI не будет 100-процентным точным, и задать ожидания в случае, если в системе AI могут возникнуть ошибки.

### <a name="during-interaction"></a>Во время взаимодействия

- **Отображение контекстно релевантной информации.** Предоставление визуальной информации, связанной с текущим контекстом и средой пользователя, например соседними гостиницами и возврат сведений, близко к целевому назначению и дате.

- **Устранение несмещений социальных сетей.** Убедитесь, что язык и поведение не предоставляют нежелательные стереотипы или смещения. Например, функция автозаполнения должна подтвердить оба пола.

### <a name="when-wrong"></a>При возникновении ошибки

- **Поддержка эффективного закрытия.** Предоставьте простой механизм для пропуска или закрытия нежелательных функций и служб.
- **Поддержка эффективного исправления.** Предоставьте интуитивно понятный способ упрощения редактирования, уточнения или восстановления.
- **Сделайте ясно, почему система была выполнена.** Оптимизируйте представление искусственного интеллекта, чтобы получить ценные сведения о утверждениях в системе AI.

### <a name="over-time"></a>Со временем

- **Помните о последних взаимодействиях.** Сохраняйте историю взаимодействий для будущего использования.
- **Изучите поведение пользователя.** Персонализация взаимодействия на основе поведения пользователя.
- **Обновление и адаптация с осторожностью.** Ограничьте неработоспособные изменения и обновите их в зависимости от профиля пользователя.
- **Поощряйте детализированные отзывы.** Собирайте отзывы пользователей от их взаимодействия с системой AI.

## <a name="a-persona-centric-trusted-ai-framework"></a>Надежная, ориентированная на пользователей инфраструктура искусственного интеллекта

![Схема доверенной инфраструктуры искусственного интеллекта на основе персонажа.](./media/ai-framework.png)

### <a name="ai-designer"></a>Конструктор искусственного интеллекта

Конструктор AI создает модель и отвечает за следующее:

- Сведения о смещении данных и проверке качества. Они обнаруживают выбросы и выполняют проверку качества данных для определения отсутствующих значений, стандартизации распределения, сопротивляются данных и создания отчетов о вариантах использования и проектов.

- Оценка данных в источнике системы для определения потенциального смещения.

- Разработка алгоритмов искусственного интеллекта для сворачивания смещений данных, таких как обнаружение группирования, группирования и нормализации (особенно в традиционных моделях машинного обучения, например на основе дерева), может привести к исключению групп миноритария из данных. Проектирование искусственного интеллекта перебирает смещения данных, группируя социальные, расовой и пол-классы на отраслевых вертикальных уровнях, которые используют защищенные сведения о работоспособности (фи) и персональные данные (PII).

- Оптимизация мониторинга и оповещений для определения утечек целевого объекта и усиления разработки модели.

- Рекомендации по созданию отчетов и аналитических данных, предлагающих детализированное понимание модели и избегая подходов к черным рамкам, которые используют важность признаков или векторов, УМАП кластеризацию, H-статистику Фридман, эффекты функций и т. д. Метрики идентификации помогают определить прогнозируемые влияния, связи и зависимости между корреляциями в сложных и современных наборах данных.

### <a name="ai-administrators-and-officers"></a>Администраторы и должностные лица искусственного интеллекта

Администратор и должностные лица AI контролируют операции искусственного интеллекта, структуры управления и аудита и метрики производительности, а также принципы реализации безопасности AI и возврата инвестиций.

- Мониторинг панели мониторинга, помогающей отслеживать модель, объединяет метрики модели для рабочих моделей и фокусируется на точности, снижении производительности, смещении данных, отклонении и изменениях скорости и ошибок вывода.

- Реализация гибкого развертывания и повторного развертывания (желательно REST API) позволяет реализовать модели в открытой независимой архитектуре, которая интегрирует модель с бизнес-процессами и создает ценность для циклов обратной связи.

- Работа над созданием границ управления моделями и наборов доступа, а затем снижается негативное влияние на бизнес и операционные системы. Стандарты управления доступом на основе ролей определяют средства управления безопасностью, которые сохраняют ограниченные рабочие среды и IP-адрес.

- Использование инфраструктур аудита и соответствия искусственного интеллекта для мониторинга разработки и изменения моделей в правилами отраслевых стандартах. Интерпретируемый и ответственный искусственный интеллект основан на мерах по объяснению, лаконичных функциях, визуализациях моделей и языковой вертикальной отрасли.

### <a name="ai-business-consumer"></a>Бизнес-потребитель искусственного интеллекта

ИСКУССТВЕНные бизнес-потребители (бизнес-эксперты) закрывают цикл обратной связи и предоставляют входные данные для конструктора искусственного интеллекта. Прогнозное принятие решений и потенциальных мер, таких как меры равноправия и безупречности, конфиденциальность и соответствие требованиям, а эффективность бизнеса — помощь в оценке систем ИИ.

- Циклы отзывов относятся к экосистеме бизнеса. Данные, отображающие смещение модели, ошибки, скорость прогнозирования и равноправие, устанавливают доверие и баланс между конструктором ии, администратором и должностными лицами. Оценка, ориентированная на человека, должна постепенно улучшать AI с течением времени, а также свести к минимуму образовательное обучение из многомерных, сложных данных (учебных курсов), которые помогут предотвратить смещенное обучение.

- Использование конструкции и средств интерпретации, которые хранят системы AI, могут быть учетными записями для возможных смещений. Проблемы с смещением и равноправием модели должны быть помечены и переданы в систему обнаружения предупреждений и аномалий, которые изучены этим поведением и автоматически отправляют адреса.

- Каждое прогнозируемое значение должно быть разбито на отдельные функции или векторы по важности или влиянию и выставлять подробные прогнозирующие пояснения, которые можно экспортировать в бизнес-отчет для проверки аудита и соответствия требованиям, прозрачности клиентов и готовности к бизнесу.

- Из-за увеличения глобальных средств безопасности и конфиденциальности, рекомендации по устранению нарушений данных во время их вывода должны соответствовать нормативам в отдельных отраслевых вертикальных чертах. Например, оповещения о несоответствии с фи и PII, нарушение законодательства национальной безопасности и многое другое.

## <a name="next-steps"></a>Дальнейшие действия

Ознакомьтесь с [руководством по человеческим AI](/ai/guidelines-human-ai-interaction/) , чтобы узнать больше о ответственном искусственном интеллекте.
