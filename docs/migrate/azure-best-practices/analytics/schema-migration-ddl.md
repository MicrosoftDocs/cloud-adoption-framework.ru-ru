---
title: Языки определения данных для миграции схемы
description: Используйте функции Azure синапсе Analytics для решения требований к высокой доступности и аварийному восстановлению.
author: v-hanki
ms.author: brblanch
ms.date: 07/14/2020
ms.topic: conceptual
ms.service: cloud-adoption-framework
ms.subservice: migrate
ms.openlocfilehash: d48135d3ba0a47df9adc6099585a66fca887b738
ms.sourcegitcommit: 07d56209d56ee199dd148dbac59671cbb57880c0
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 08/26/2020
ms.locfileid: "88882317"
---
<!-- cSpell:ignore DDLs Attunity "Attunity Replicate" "Attunity Visibility" Inmon Denodo Teradata Netezza Wherescape DMVs multinode equi Datometry -->

# <a name="data-definition-languages-for-schema-migration"></a>Языки определения данных для переноса схемы

В этой статье описываются вопросы проектирования и параметры производительности для языков определения данных (означающего) при переносе схем в Azure синапсе Analytics.

## <a name="design-considerations"></a>Рекомендации по проектированию

### <a name="preparation-for-migration"></a>Подготовка к миграции

При подготовке к переносу существующих данных в Azure синапсе Analytics важно четко определить область действия упражнения (особенно для первоначального проекта миграции). Время, затраченное на понимание того, как объекты базы данных и связанные процессы будут перенесены, может уменьшить усилия и риск позже в проекте.

Создайте инвентаризацию объектов базы данных для переноса. В зависимости от исходной платформы эта инвентаризация будет включать в себя некоторые или все из следующих объектов:

- Таблицы
- Представления
- Индексы
- Функции
- Хранимые процедуры
- Распределение и секционирование данных

Основные сведения об этих объектах должны включать такие метрики, как количество строк, физический размер, коэффициенты сжатия данных и зависимости объектов. Эти сведения должны быть доступны через запросы к таблицам системных каталогов в исходной системе. Метаданные системы являются лучшим источником для этих сведений. Внешняя документация может быть устаревшей и не синхронизирована с изменениями, примененными к структуре данных с момента первоначальной реализации.

Вы также можете анализировать фактическое использование объектов из журналов запросов или использовать инструментарий от партнеров Майкрософт, например Attunity Visibility, для помощи. Возможно, некоторые таблицы не нужно переносить, так как они больше не используются в рабочих запросах.

Сведения о размере данных и рабочей нагрузке важны для Azure синапсе Analytics, так как они помогают определить соответствующие конфигурации. Одним из примеров является требуемый уровень параллелизма. Понимание ожидаемого роста данных и рабочих нагрузок может повлиять на рекомендуемую целевую конфигурацию, и рекомендуется также использовать эту информацию.

При использовании томов данных для оценки хранилища, необходимого для новой целевой платформы, важно понимать степень сжатия данных, если таковая имеется, в базе данных источника. Простое получение объема хранилища, используемого в исходной системе, скорее всего, является ложным основанием для изменения размера. Сведения о мониторинге и метаданных могут помочь в определении несжатого размера необработанных данных и переголовков для индексирования, репликации данных, ведения журнала или других процессов в текущей системе.

Несжатый размер необработанных данных переносимых таблиц является хорошей отправной точкой для оценки хранилища, необходимого в новой целевой среде Azure синапсе Analytics.

Новая Целевая платформа также будет включать коэффициент сжатия и затраты на индексирование, но они, вероятно, будут отличаться от исходной системы. Цены на хранилище Azure синапсе Analytics также включают в себя семь дней резервного копирования моментальных снимков. По сравнению с существующей средой это может повлиять на общую стоимость хранилища.

Можно отложить настройку производительности для модели данных до окончания процесса миграции и время, когда реальные объемы данных находятся в хранилище данных. Однако рекомендуется реализовать некоторые параметры настройки производительности ранее.

Например, в Azure синапсе Analytics имеет смысл определить небольшие таблицы измерений как реплицированные таблицы и определить большие таблицы фактов как кластеризованные индексы columnstore. Аналогичным образом, индексы, определенные в исходной среде, дают хорошее представление о том, какие столбцы могут оказаться полезными при индексировании в новой среде. Использование этих сведений при первоначальном определении таблиц перед загрузкой позволит сэкономить время позже.

Рекомендуется измерять коэффициент сжатия и накладные расходы на индексы для собственных данных в Azure синапсе Analytics по мере продвижения проекта миграции. Эта мера позволяет планировать будущие ресурсы.

Можно упростить существующее хранилище данных до миграции, уменьшая сложность для упрощения миграции. Эти усилия могут включать:

- Удаление или архивация неиспользуемых таблиц перед миграцией во избежание переноса неиспользуемых данных. Архивация в хранилище BLOB-объектов Azure и определение данных в виде внешней таблицы может привести к снижению затрат на доступ к данным.
- Преобразование физических киосков данных в виртуальные киоски данных с помощью программного обеспечения виртуализации данных для сокращения числа миграций. Это преобразование также повышает гибкость и снижает совокупную стоимость владения. Это можно рассматривать как модернизации во время миграции.

Одной из целей миграции можно также модернизировать хранилище, изменив базовую модель данных. Одним из примеров является перемещение из модели данных в стиле Inmon в подход к хранилищу данных. Следует принять решение об этом в рамках этапа подготовки и внедрить стратегию перехода в план миграции.

Рекомендуемый подход в этом сценарии заключается в том, чтобы сначала перенести модель данных на новую платформу, а затем перейти к новой модели в Azure синапсе Analytics. Используйте характеристики масштабируемости и производительности платформы для выполнения преобразования без влияния на исходную систему.

### <a name="data-model-migration"></a>Перенос модели данных

В зависимости от платформы и источников исходной системы модель данных некоторых или всех частей может уже быть в форме схемы «звезда» или «снежинка». Если это так, вы можете напрямую перенести его в Azure синапсе Analytics, как есть. Этот сценарий является самым простым и низким риском для достижения. Миграция "как есть" также может быть первой стадией более сложной миграции, которая включает переход на новую базовую модель данных, такую как хранилище данных, как описано выше.

Любой набор реляционных таблиц и представлений можно перенести в Azure синапсе Analytics. Для рабочих нагрузок аналитических запросов к большому набору данных модель данных типа «звезда» или «снежинка» обычно обеспечивает максимальную общую производительность. Если исходная модель данных еще не находится в этой форме, то, возможно, следует использовать процесс миграции для повторной обработки модели.

Если проект миграции включает какие-либо изменения в модель данных, рекомендуется выполнить эти изменения в новой целевой среде. То есть сначала необходимо перенести существующую модель, а затем воспользоваться возможностями и гибкостью Azure синапсе Analytics для преобразования данных в новую модель. Такой подход сокращает влияние на существующую систему и использует производительность и масштабируемость Azure синапсе Analytics для быстрого и экономичного внесения любых изменений.

Существующую систему можно перенести как несколько уровней (например, уровень приема и размещения данных, уровень хранилища данных и уровень подготовки отчетов или киоска данных). Каждый слой состоит из реляционных таблиц и представлений. Хотя вы можете перенести все эти данные в Azure синапсе Analytics как есть, это может быть более экономичным и надежным для использования некоторых функций и возможностей экосистемы Azure. Например:

- Прием **и промежуточное хранение данных:** Хранилище BLOB-объектов Azure в сочетании с Polybase можно использовать для быстрой загрузки параллельных данных для части ETL (извлечение, преобразование, Загрузка) или ELT (извлечение, Загрузка, преобразование), а не реляционных таблиц.
- **Слой отчетов и киоски данных:** Характеристики производительности Azure синапсе Analytics могут устранить необходимость физического создания экземпляров агрегированных таблиц для целей отчетности или киосков данных. Их можно реализовать в качестве представлений в основном хранилище данных или на уровне виртуализации данных стороннего производителя. На базовом уровне можно достичь процесса переноса данных с предысторией и, возможно, добавочных обновлений, как показано на этой схеме:

   ![Схема, иллюстрирующая современное хранилище данных.](../../../_images/analytics/schema-migration-ddl.png)

Если вы можете использовать эти или аналогичные подходы, количество перемещаемых таблиц уменьшится. Некоторые процессы могут быть упрощены или исключены, опять же сокращая рабочую нагрузку миграции. Применимость этих подходов зависит от конкретного варианта использования. Но общий принцип заключается в том, чтобы использовать функции и средства экосистемы Azure, где это возможно, чтобы сократить рабочую нагрузку миграции и создать экономичную целевую среду. Это также относится и к другим функциям, таким как резервное копирование и восстановление, Управление рабочими процессами и мониторинг.

Продукты и услуги, предоставляемые партнерами Майкрософт, могут помочь в переносе хранилища данных, а в некоторых случаях автоматизируют части процесса. Если существующая система включает в себя сторонний продукт ETL, он может уже поддерживать Azure синапсе Analytics в качестве целевой среды. Существующие рабочие процессы ETL можно перенаправить в новое целевое хранилище данных SQL Azure.

### <a name="data-marts-physical-or-virtual"></a>Киоски данных: физические или виртуальные

В организациях, использующих более старые среды хранилища данных, обычно создаются киоски данных, которые предоставляют свои отделы или бизнес-функции с высокой производительностью нерегламентированных запросов и производительности отчетов. Киоск данных обычно состоит из подмножества хранилища данных, содержащего статистические версии исходных данных. Ее форма, как правило, многомерная модель данных, позволяет пользователям легко запрашивать данные и получать быстрое время отклика от удобных для пользователя средств, таких как Tableau, Микростратеги или Microsoft Power BI.

Киоски данных используются для предоставления данных в пригодной для использования форме, даже если базовая модель данных хранилища отличается (например, хранилище данных). Этот подход также известен как модель с тремя уровнями.

Вы можете использовать отдельные киоски данных для отдельных подразделений в Организации для реализации надежной режимы безопасности данных. Например, вы можете разрешить пользователю доступ к конкретным киоскам данных, которые имеют отношение к ним, а также исключить, запутывания или Анонимизация конфиденциальные данные.

Если эти киоски данных реализованы как физические таблицы, им требуются дополнительные ресурсы хранилища для их размещения и дополнительной обработки для регулярной сборки и обновления. Физические таблицы показывают, что данные в киоске являются текущими последними операциями обновления, поэтому они могут не подойти для панелей мониторинга с очень энергонезависимыми данными.

С появлением относительно дешевых масштабируемых архитектур (MPP), таких как Azure синапсе Analytics и их характеристик производительности, вы можете предоставить функциональные возможности киоска данных без необходимости создания экземпляра киоска в виде набора физических таблиц. Это достигается за счет эффективного виртуализации киосков данных с помощью одного из следующих методов:

- Представления SQL в основном хранилище данных.
- Уровень виртуализации, использующий такие функции, как представления в Azure синапсе Analytics или сторонние продукты виртуализации, такие как Денодо.

Такой подход упрощает или исключает потребность в дополнительных объемах хранилища и статистической обработке. Он сокращает общее число переносимых объектов базы данных.

Еще одним преимуществом подхода к хранилищу данных является емкость для выполнения таких операций, как объединение и агрегирование на больших объемах данных. Например, реализация логики агрегирования и объединения на уровне виртуализации и отображение внешних отчетов в виртуализированном представлении помещает надежную обработку, необходимую для создания этих представлений в хранилище данных.

Основные драйверы для реализации физической или виртуальной киоска данных:

- Более динамичность. Виртуальный киоск данных проще изменять, чем физические таблицы и связанные процессы ETL.
- Снижение совокупной стоимости владения из-за меньшего количества хранилищ данных и копий данных в виртуализованной реализации.
- Исключение заданий ETL для переноса и упрощения архитектуры хранилища данных в виртуализированной среде.
- Производительность. Исторически, физические киоски данных были более надежными. Продукты виртуализации теперь реализуют методы интеллектуального кэширования для устранения этой проблемы.

Можно также использовать виртуализацию данных для согласованного представления данных пользователям во время миграции проекта.

### <a name="data-mapping"></a>Сопоставление данных

#### <a name="key-and-integrity-constraints-in-azure-synapse-analytics"></a>Ограничения ключей и целостности в Azure синапсе Analytics

Ограничения первичного ключа и внешнего ключа в настоящее время не применяются в Azure синапсе Analytics. Однако можно включить определение `PRIMARY KEY` в `CREATE TABLE` инструкцию с `NOT ENFORCED` предложением. Это означает, что сторонние продукты отчетов могут использовать метаданные для таблицы, чтобы понять ключи в модели данных и, таким образом, создавать наиболее эффективные запросы.

#### <a name="data-type-support-in-azure-synapse-analytics"></a>Поддержка типов данных в Azure синапсе Analytics

Некоторые старые системы баз данных включают поддержку типов данных, которые не поддерживаются напрямую в Azure синапсе Analytics. Эти типы данных можно обменять с помощью поддерживаемого типа данных для хранения данных в виде или путем преобразования данных в поддерживаемый тип данных.

Ниже приведен алфавитный список поддерживаемых типов данных.

<!-- TODO: Review format of this list. Are the arguments necessary for this list? -->

<!-- docsTest:disable -->

- `bigint`
- `binary [ (n) ]`
- `bit`
- `char [ (n) ]`
- `date`
- `datetime`
- `datetime2 [ (n) ]`
- `datetimeoffset [ (n) ]`
- `decimal [ (precision [, scale ]) ]`
- `float [ (n) ]`
- `int`
- `money`
- `nchar [ (n) ]`
- `numeric [ (precision [ , scale ]) ]`
- `nvarchar [ (n | MAX) ]`
- `real [ (n) ]`
- `smalldatetime`
- `smallint`
- `smallmoney`
- `time [ (n) ]`
- `tinyint`
- `uniqueidentifier`
- `varbinary [ (n | MAX) ]`
- `varchar [ (n | MAX) ]`

<!-- docsTest:enable -->

В следующей таблице перечислены распространенные типы данных, которые в настоящее время не поддерживаются, а также рекомендованный подход к хранению этих типов в Azure синапсе Analytics. Дополнительные сведения о конкретных средах, таких как Teradata или Netezza, см. в соответствующих документах.

| Неподдерживаемые типы данных | Обходной путь |
|--|--|
| `geometry`              | `varbinary`                                                       |
| `geography`             | `varbinary`                                                       |
| `hierarchyid`           | `nvarchar(4000)`                                                  |
| `image`                 | `varbinary`                                                       |
| `text`                  | `varchar`                                                         |
| `ntext`                 | `nvarchar`                                                        |
| `sql_variant`           | Разделить столбец на несколько строго типизированных столбцов                |
| `table`                 | Преобразовать во временные таблицы                                     |
| `timestamp`             | Переработайте код для использования `datetime2` и `CURRENT_TIMESTAMP` функции |
| `xml`                   | `varchar`                                                         |
| Определяемый пользователем тип     | Преобразовать обратно в собственный тип данных, если это возможно              |

#### <a name="potential-data-issues"></a>Потенциальные проблемы с данными

В зависимости от исходной среды некоторые проблемы могут вызвать проблемы при переносе данных:

- В способе `NULL` обработки данных в разных продуктах баз данных могут быть незаметные различия. К примерам относятся порядок сортировки и обработка пустых символьных строк.
- `DATE``TIME`данные,, `INTERVAL` и `TIME ZONE` связанные функции могут сильно отличаться от продукта к продукту.

Тщательно протестируйте их, чтобы определить, достигнут ли желаемый результат в целевой среде. В упражнении по миграции можно выявить ошибки или неправильные результаты, которые в настоящее время являются частью существующей исходной системы, а процесс миграции — хорошая возможность исправить аномалии.

#### <a name="best-practices-for-defining-columns-in-azure-synapse-analytics"></a>Рекомендации по определению столбцов в Azure синапсе Analytics

Обычно устаревшие системы содержат столбцы с неэффективными типами данных. Например, можно найти поле, определенное как, `VARCHAR(20)` когда фактические значения данных помещаются в `CHAR(5)` поле. Или можно найти использование `INTEGER` полей, если все значения помещаются в `SMALLINT` поле. Недостаточные типы данных могут привести к неэффективному функционированию хранилища и производительности запросов, особенно в больших таблицах фактов.

Мы рекомендуем проверить и рационализировать текущие определения данных во время миграции. Эти задачи можно автоматизировать с помощью SQL-запросов, чтобы найти максимальное числовое значение или длину символов в поле данных и сравнить результат с типом данных.

Как правило, рекомендуется максимально сокращать общую длину строки для таблицы. Для оптимальной производительности запросов можно использовать наименьший тип данных для каждого столбца, как описано выше. Рекомендуемый подход к загрузке данных из внешних таблиц в Azure синапсе Analytics заключается в использовании служебной программы Polybase, которая поддерживает максимальную длину строки, равную 1 мегабайт (МБ). Polybase не загрузит таблицы со строками, превышающими 1 МБ, и вместо этого следует использовать программу по копированию.

Для наиболее эффективного выполнения объединения Определите столбцы обеих сторон объединения как один и тот же тип данных. Если ключ таблицы измерения определен как `SMALLINT` , то соответствующие ссылочные столбцы в таблицах фактов, использующих это измерение, также должны быть определены как `SMALLINT` .

Старайтесь не определять поля символов с большим размером по умолчанию. Если максимальный размер данных в поле составляет 50 символов, используйте `VARCHAR(50)` . Аналогично, не используйте, `NVARCHAR` Если `VARCHAR` будет достаточно. `NVARCHAR` хранит данные в Юникоде, чтобы разрешить разные наборы символов языка. `VARCHAR` сохраняет данные ASCII и занимает меньше пространства.

## <a name="summary-of-design-recommendations"></a>Сводка рекомендаций по проектированию

Не переносите ненужные объекты или процессы. Используйте встроенные функции и функции в целевой среде Azure, где это необходимо, чтобы уменьшить фактическое количество объектов и процессов для миграции. Используйте уровень виртуализации, чтобы сократить или исключить количество физических киосков данных, которые будут перенесены, и отложить обработку в хранилище данных.

Автоматизируйте везде, где это возможно, и используйте метаданные из системных каталогов в исходной системе для создания означающего для целевой среды. Если это возможно, также Автоматизируйте создание документов. Такие партнеры корпорации Майкрософт, как Вхерескапе, могут предоставлять специализированные средства и службы для облегчения автоматизации.

Выполните необходимые изменения модели данных или оптимизацию сопоставления данных на целевой платформе. Вы можете повысить эффективность этих изменений в Azure синапсе Analytics. Такой подход снижает влияние на исходные системы, которые, возможно, уже работают, близко к полной емкости.

## <a name="performance-options"></a>Параметры производительности

В этом разделе описываются функции, доступные в Azure синапсе Analytics, которые можно использовать для повышения производительности модели данных.

### <a name="general-approach"></a>Общий подход

Функции платформы запускают настройку производительности для базы данных, которая будет перенесена. Примерами такой настройки производительности являются индексы, секционирование данных и распределение данных. При подготовке к миграции документирование настройки может захватывать и раскрывать оптимизации, которые можно применять в целевой среде Azure синапсе Analytics.

Например, наличие неуникального индекса в таблице может указывать на то, что поля, используемые в индексе, часто используются для фильтрации, группирования или объединения. В новой среде это все равно будет иметь место, поэтому при выборе полей для индексирования следует помнить об этом. Рекомендации по миграции для конкретных исходных платформ, таких как Teradata и Netezza, подробно описаны в отдельных документах.

Используйте производительность и масштабируемость целевой среды Azure синапсе Analytics, чтобы поэкспериментировать с различными параметрами производительности, такими как распределение данных. Определите оптимальный выбор альтернативных подходов (например, репликация и распределение хэша для большой таблицы измерения). Это не значит, что данные должны быть перезагружены из внешних источников. Проще и быстро тестировать альтернативные подходы в Azure синапсе Analytics, создавая копии любой таблицы с различными вариантами секционирования или распределения с помощью `CREATE TABLE AS SELECT` инструкции.

Используйте средства мониторинга, предоставляемые средой Azure, чтобы понять, как выполняются запросы и в каких случаях могут возникнуть узкие места. Средства также доступны сторонним партнерам корпорации Майкрософт для предоставления панелей мониторинга и автоматического управления ресурсами и оповещений.

Каждая операция SQL в Azure синапсе Analytics и ресурс, например память или ЦП, используемые этим запросом, заносится в системные таблицы. Ряд динамических административных представлений упрощает доступ к этим сведениям.

В следующих разделах объясняются основные параметры в хранилище данных SQL Azure для настройки производительности запросов. В существующих средах будут содержаться сведения о потенциальной оптимизации в целевой среде.

### <a name="temporary-tables"></a>Временные таблицы

Azure синапсе Analytics поддерживает временные таблицы, которые видны только сеансу, в котором они были созданы. Они существуют в течение сеанса пользователя и автоматически удаляются в конце сеанса.

Чтобы создать временную таблицу, перед именем таблицы добавьте в префикс хэш-символ ( `#` ). Можно использовать все стандартные варианты индексирования и распространения с временными таблицами, как описано в следующем разделе.

Временные таблицы имеют некоторые ограничения.

- Переименование не допускается.
- Просмотр или секционирование не разрешено.
- Изменение разрешений запрещено.

Временные таблицы обычно используются в обработке ETL/ELT, где временные промежуточные результаты используются как часть процесса преобразования.

### <a name="table-distribution-options"></a>Параметры распространения таблицы

Azure синапсе Analytics — это система баз данных MPP, которая обеспечивает производительность и масштабируемость за счет параллельного выполнения на нескольких вычислительных узлах.

Идеальным сценарием обработки для выполнения SQL-запроса в среде с многоузловой средой является балансировка рабочей нагрузки и предоставление всем узлам одинакового объема данных для обработки. Этот подход также позволяет свести или уменьшить объем данных, которые должны быть перемещены между узлами для удовлетворения запроса.

Достичь идеального сценария может быть непросто, поскольку часто возникают статистические вычисления в типичных аналитических запросах и несколько соединений между несколькими таблицами, как между таблицами фактов и измерений.

Одним из способов влияния обработки запросов является использование параметров распространения в Azure синапсе Analytics для указания места хранения отдельных строк данных каждой таблицы. Например, предположим, что две большие таблицы соединены со столбцом данных `CUSTOMER_ID` . Распределение двух таблиц по `CUSTOMER_ID` столбцам при каждом выполнении объединения позволяет гарантировать, что данные из каждой стороны объединения будут размещены на одном и том же узле обработки. Этот метод устраняет необходимость перемещения данных между узлами. Спецификация распределения для таблицы определена в `CREATE TABLE` инструкции.

В следующих разделах описаны доступные варианты распространения и рекомендации по их использованию. Можно изменить распределение таблицы после начальной загрузки, если это необходимо: повторно создать таблицу с новым распределением с помощью `CREATE TABLE AS SELECT` инструкции.

#### <a name="round-robin"></a>Циклический перебор

Распределение таблиц с циклическим перебором является параметром по умолчанию и равномерно распределяет данные между узлами в системе. Этот метод подходит для быстрой загрузки данных и для недостаточного объема данных и не имеет очевидных кандидатов для хэширования. Он часто используется для промежуточных таблиц в рамках процесса ETL или ELT.

#### <a name="hashed"></a>Хэшируется

Система назначает строку хэш-контейнеру, задаче на основе алгоритма хэширования, применяемого к определяемому пользователем ключу, как `CUSTOMER_ID` в предыдущем примере. Затем контейнер назначается определенному узлу, и все строки данных, распределенные по одному и тому же значению, находятся на одном и том же узле обработки.

Этот метод полезен для больших таблиц, которые часто соединяются или объединяются по ключу. Если возможно, другие большие таблицы, которые необходимо объединить, должны быть хэшированы по тому же ключу. Если существует несколько кандидатов для хэш-ключа, выберите наиболее часто соединяемый.

Хэш-столбец не должен содержать значения NULL и обычно не является датой, так как многие запросы фильтруются по дате. Хэширование обычно более эффективно, если ключ для хэширования является целочисленным значением вместо `CHAR` или `VARCHAR` . Старайтесь не выбирать ключи с сильно отклоненным диапазоном значений, например, если небольшое количество ключевых значений представляет большой процент строк данных.

#### <a name="replicated"></a>Реплицированный

Если выбрать параметр реплицировать в качестве параметра распределения для таблицы, то полная копия этой таблицы будет реплицирована на каждый вычислительный узел для обработки запросов.

Этот подход удобен для относительно небольших таблиц (обычно менее 2 ГБ), которые относительно статичны и часто соединяются с большими таблицами через эквивалентное соединение. Эти таблицы часто представляют собой многомерные таблицы в схеме типа «звезда».

### <a name="indexing"></a>Индексация

Azure синапсе Analytics включает параметры для индексирования данных в больших таблицах, чтобы сократить количество ресурсов и время, необходимое для получения записей.

- Кластеризованный индекс columnstore
- Кластеризованный индекс
- Некластеризованный индекс

Неиндексированный параметр, `HEAP` существует для таблиц, которые не выигрывают от каких-либо параметров индекса. Использование индексов — это компромисс между улучшением времени запроса и более длительным временем загрузки и использованием большего объема хранилища. Индексы часто ускоряют `SELECT` `UPDATE` операции,, `DELETE` и `MERGE` в больших таблицах, влияющих на небольшой процент строк данных, и позволяют сократить полные Просмотры таблиц.

Индексы создаются автоматически, `UNIQUE` Если `PRIMARY KEY` для столбцов определены ограничения или.

#### <a name="clustered-columnstore-index"></a>Кластеризованный индекс columnstore

Кластеризованный индекс columnstore является параметром индексирования по умолчанию в Azure синапсе Analytics. Он обеспечивает наилучшее сжатие и производительность запросов для больших таблиц. Для небольших таблиц менее 60 000 000 строк эти индексы не являются эффективными, поэтому следует использовать параметр HEAP. Аналогичным образом, куча или временная таблица могут быть более эффективны, если данные в таблице являются временными и частью процесса ETL/ELT.

#### <a name="clustered-index"></a>Кластеризованный индекс

Если существует требование регулярного извлечения одной строки или небольшого количества строк из большой таблицы на основе условия строгого фильтра, кластеризованный индекс может оказаться более эффективным, чем кластеризованный индекс columnstore. Для каждой таблицы допускается только один кластеризованный индекс.

#### <a name="non-clustered-index"></a>Некластеризованный индекс

Некластеризованные индексы похожи на кластеризованные индексы в том, что они могут ускорить получение отдельных строк или небольшое количество строк на основе условия фильтра. На внутреннем уровне некластеризованные индексы хранятся отдельно от данных, и для таблицы могут быть определены несколько некластеризованных индексов. Однако для каждого дополнительного индекса потребуется больше места для хранения данных и будет снижена пропускная способность при вставке или загрузке.

#### <a name="heap"></a>Куча

В таблицах кучи не взимается нагрузка, связанная с созданием и обслуживанием индексов во время загрузки данных. Они могут помочь быстро загружать временные данные во время процессов, включая процессы ELT. Кэширование также может помочь при немедленном чтении данных. Так как кластеризованные индексы columnstore являются неэффективными ниже 60 000 000 строк, таблицы кучи также могут помочь хранить таблицы со строками, размер которых меньше этого.

### <a name="data-partitioning"></a>Секционирование данных

В хранилище данных предприятия таблицы фактов могут содержать много миллиардов строк. Секционирование — это способ оптимизации обслуживания и выполнения запросов к этим таблицам путем разбиения их на отдельные части для уменьшения объема данных, обрабатываемых при выполнении запросов. Спецификация секционирования для таблицы определена в `CREATE TABLE` инструкции.

Для секционирования можно использовать только одно поле для каждой таблицы. Часто это поле даты, поскольку многие запросы фильтруются по датам или диапазонам дат. При необходимости можно изменить секционирование таблицы после начальной загрузки, повторно создав таблицу с новым распределением с помощью `CREATE TABLE AS SELECT` инструкции.

#### <a name="partitioning-for-query-optimization"></a>Секционирование для оптимизации запросов

Если запросы к большой таблице фактов часто фильтруются по определенному столбцу данных, секционирование по этому столбцу может значительно сократить объем данных, которые необходимо обработать для выполнения запросов. Распространенный пример — использование поля даты для разбиения таблицы на группы меньшего размера. Каждая группа содержит данные за один день. Если запрос содержит `WHERE` предложение, которое фильтрует по дате, к ним должны обращаться только секции, соответствующие фильтру даты.

#### <a name="partitioning-for-optimization-of-table-maintenance"></a>Секционирование для оптимизации обслуживания таблиц

В средах хранилища данных обычно поддерживается пошаговое окно подробных данных фактов. Например, транзакции продажи, которые возвращаются за пять лет. При секционировании по дате продажи удаление старых данных, находящихся за пределами окна, станет гораздо более эффективным. Удаление самой старой секции выполняется быстрее и использует меньше ресурсов, чем удаление всех отдельных строк.

### <a name="statistics"></a>Статистика

При отправке запроса в Azure синапсе Analytics он сначала обрабатывается оптимизатором запросов. Оптимизатор определяет лучшие внутренние методы для эффективного выполнения запроса.

Оптимизатор сравнивает различные планы выполнения запросов, доступные на основе алгоритма, основанного на стоимости. Точность оценки затрат зависит от доступной статистики. Рекомендуется обеспечить актуальность статистики.

Если этот параметр включен, в Azure синапсе Analytics `AUTO_CREATE_STATISTICS` будет активировано автоматическое обновление статистики. Можно также создать или обновить статистику вручную с помощью `CREATE STATISTICS` команды.

Обновление статистики при значительном изменении содержимого, например в ежедневном обновлении. Это обновление можно встроить в процесс ETL.

Все таблицы в базе данных должны иметь статистику по крайней мере с одним столбцом. Это гарантирует, что оптимизатор может получить доступ к основным сведениям, таким как количество строк и размер таблицы. Другие столбцы, для которых должна быть собрана статистика, — это столбцы, указанные в `JOIN` `DISTINCT` обработке,, `ORDER BY` и `GROUP BY` .

### <a name="workload-management"></a>Управление рабочей нагрузкой

Azure синапсе Analytics включает в себя комплексные функции для управления использованием ресурсов в смешанных рабочих нагрузках. Создание классов ресурсов для различных типов рабочей нагрузки, таких как запросы и загрузка данных, помогает управлять рабочей нагрузкой. Он устанавливает ограничения на количество параллельно выполняемых запросов и на ресурсы вычислений, назначенные каждому запросу. Существует компромисс между памятью и параллелизмом.

- Меньшие классы ресурсов уменьшают максимальный объем памяти на запрос, но увеличивают параллелизм.
- Большие классы ресурсов увеличивают максимальный объем памяти на запрос, но уменьшают параллелизм.

### <a name="performance-recommendations"></a>Рекомендации по производительности

Используйте методы улучшения производительности, такие как индексы или распределение данных, чтобы оценить кандидаты для похожих методов в новой целевой среде, но тест производительности, чтобы убедиться, что они необходимы в Azure синапсе Analytics. `COLLECT STATISTICS`Выполните сборку шагов в процессах ETL/ELT, чтобы обеспечить актуальность статистики, или выберите автоматическое создание статистики.

Ознакомьтесь с параметрами настройки, доступными в Azure синапсе Analytics, и характеристиками производительности связанных служебных программ, например Polybase для быстрой загрузки данных с параллельной обработкой. Используйте эти параметры для создания эффективной сквозной реализации.

Используйте гибкость, масштабируемость и производительность среды Azure, чтобы реализовать любые изменения модели данных или параметры настройки производительности на месте. Эти усилия снижают влияние на существующие исходные системы.

Общие сведения о динамических административных представлениях, доступных в Azure синапсе Analytics. Эти представления предоставляют сведения об использовании ресурсов в масштабе всей системы и подробные сведения о выполнении отдельных запросов.

Изучите классы ресурсов Azure и выделите их соответствующим образом, чтобы обеспечить эффективное управление смешанными рабочими нагрузками и параллелизмом.

Рассмотрите возможность использования уровня виртуализации в рамках среды Azure синапсе Analytics. Это позволяет защитить изменения в реализации хранилища от бизнес-пользователей и средств создания отчетов.

Изучите средства миграции и службы, предоставляемые партнером, такие как Qlik Sense replicate для миграций Майкрософт, Вхерескапе и Datometry. Эти службы могут автоматизировать часть процесса миграции и сократить затраченное время и риск, связанные с проектом миграции.
