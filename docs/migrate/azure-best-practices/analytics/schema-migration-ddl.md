---
title: Языки определения данных для миграции схемы (означающего)
description: Используйте функции Azure синапсе для решения требований к высокой доступности и аварийному восстановлению.
author: v-hanki
ms.author: brblanch
ms.date: 07/14/2020
ms.topic: conceptual
ms.service: cloud-adoption-framework
ms.subservice: migrate
ms.openlocfilehash: 50c4233325ffd1663331d0bf36d5fcb4b32cda7b
ms.sourcegitcommit: 9163a60a28ffce78ceb5dc8dc4fa1b83d7f56e6d
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 07/17/2020
ms.locfileid: "86452156"
---
<!-- cSpell:ignore DDLs Attunity "Attunity Replicate" "Attunity Visibility" Inmon Denodo Teradata Netezza Wherescape DMVs multinode equi Datometry -->

# <a name="schema-migration-data-definition-languages-ddls"></a>Языки определения данных для миграции схемы (означающего)

## <a name="design-considerations"></a>Рекомендации по проектированию

### <a name="preparation-for-migration"></a>Подготовка к миграции

При подготовке к переносу существующих данных в Azure синапсе Analytics важно четко определить область действия упражнения (особенно для первоначального проекта миграции). Время, затраченное на понимание объектов базы данных и связанных с ними процессов, будет взимать дивиденды в целях сокращения усилий и риска позже в проекте.

Создайте инвентаризацию объектов базы данных для переноса. В зависимости от исходной платформы эта инвентаризация будет включать в себя некоторые или все из следующих объектов:

- Таблицы
- Представления
- Индексы
- Функции
- Хранимые процедуры
- Распределение и секционирование данных

Основные сведения об этих объектах (включая метрики, такие как количество строк, физический размер, коэффициенты сжатия данных и зависимости объектов) должны быть доступны через запросы к таблицам системных каталогов в исходной системе. Метаданные системы являются лучшим источником для этих сведений. Внешняя документация может быть устаревшей и не синхронизирована с изменениями, примененными к структуре данных с момента первоначальной реализации.

Кроме того, можно анализировать фактическое использование объектов из журналов запросов или использовать средства от партнеров Майкрософт, чтобы помочь, например, Attunity видимость. Возможно, некоторые таблицы не нужно переносить, так как они больше не используются в рабочих запросах.

Размер данных и сведения о рабочей нагрузке (например, уровни параллелизма) важны, так как она используется для определения соответствующей конфигурации для Azure синапсе Analytics. Также рекомендуется понимать ожидаемые объемы данных и рабочей нагрузки, так как это может также повлиять на рекомендуемую целевую конфигурацию.

При использовании томов данных для оценки объема хранилища, необходимого для новой целевой платформы, важно понимать степень сжатия данных (если таковая имеется) в базе данных-источнике. Простое получение объема хранилища, используемого в исходной системе, скорее всего, является ложным основанием для изменения размера. Данные мониторинга и метаданных должны быть доступны для определения несжатого размера необработанных данных, а также любых заголовков для индексирования, репликации данных, ведения журнала или других процессов в текущей системе.

Несжатый размер необработанных данных переносимых таблиц является хорошей отправной точкой для оценки хранилища, необходимого в новой целевой среде Azure синапсе Analytics.

Также будет использоваться коэффициент сжатия, а также затраты на индексирование на новой целевой платформе, но они, скорее всего, будут отличаться от исходной системы. Цены на хранилище Azure синапсе Analytics также включают в себя семь дней резервного копирования моментальных снимков. Это может оказать влияние на общую стоимость хранилища, требуемую по сравнению с существующей средой.

Процесс настройки производительности модели данных может остаться до тех пор, пока процесс миграции не покончится, так что он будет выполняться при наличии в хранилище данных реальных томов данных. Но в процессе рекомендуется реализовать некоторые параметры настройки производительности. Например, в Azure синапсе Analytics, как правило, имеет смысл определить небольшие таблицы измерений как реплицированные таблицы и определить большие таблицы фактов как кластеризованные индексы columnstore. Аналогичным образом, индексы, определенные в исходной среде, дают хорошее представление о том, какие столбцы могут оказаться полезными при индексировании в новой среде. Использование этих сведений при первоначальном определении таблиц до загрузки позволит сэкономить время позже.

Рекомендуется измерять коэффициент сжатия и накладные расходы на индексы для собственных данных в Azure синапсе Analytics по мере продвижения проекта миграции. Эта мера позволяет планировать будущие ресурсы.

Чтобы упростить миграцию, можно просто использовать имеющееся хранилище данных до миграции. Это может быть:

- Удаление или архивация неиспользуемых таблиц перед миграцией во избежание переноса неиспользуемых данных. Архивация в хранилище BLOB-объектов Azure и определение данных в виде внешней таблицы может привести к недоступности данных, но с меньшими затратами.
- Преобразование физических киосков данных в виртуальные киоски данных с помощью программного обеспечения виртуализации данных для сокращения числа миграций. Это преобразование также повышает гибкость и снижает совокупную стоимость владения и может рассматриваться как модернизации во время миграции.

Одной из целей миграции можно также модернизировать хранилище, изменив базовую модель данных, например переход от модели данных Inmon Style к подходу к хранилищу данных. Это должно быть принято в рамках подготовительной фазы, и стратегия перехода должна быть включена в план миграции. Рекомендуемый подход в этом сценарии заключается в том, чтобы сначала перенести модель данных в новую платформу, а затем выполнить переход на новую модель в Azure синапсе Analytics, используя характеристики масштабируемости и производительности платформы для выполнения преобразования без влияния на исходную систему.

### <a name="data-model-migration"></a>Перенос модели данных

В зависимости от платформы и источников исходной системы модель данных некоторых или всех частей может уже быть в форме схемы «звезда» или «снежинка». Если это так, можно напрямую перенести его в Azure синапсе Analytics, как есть. Этот сценарий является самым простым и низким риском для достижения. Миграция "как есть" также может быть первой стадией более сложной миграции, которая включает переход на новую базовую модель данных, такую как хранилище данных, как описано выше.

Хотя любой набор реляционных таблиц и представлений можно перенести в Azure синапсе Analytics, для рабочих нагрузок аналитических запросов к большому набору данных модель данных типа «звезда» или «снежинка» обычно обеспечивает максимальную общую производительность. Если исходная модель данных еще не находится в этой форме, то, возможно, следует использовать процесс миграции для реконструирования модели.

Если какие-либо изменения в модели данных выполняются в рамках проекта миграции, рекомендуется выполнить эти изменения в новой целевой среде, то есть сначала перенести существующую модель, а затем использовать мощь и гибкость Azure синапсе Analytics для преобразования данных в новую модель. Такой подход сокращает влияние на существующую систему и использует производительность и масштабируемость Azure синапсе Analytics для быстрого и экономичного внесения любых изменений.

Существующая система может быть реализована как несколько уровней (например, уровень приема и размещения данных, уровень хранилища данных и отчеты или уровень киосков данных), каждый из которых состоит из нескольких реляционных таблиц и представлений. Хотя все это можно перенести в Azure синапсе Analytics "как есть", это может быть более экономичным и эффективно использовать некоторые функции и возможности экосистемы Azure, а не все непосредственно. Пример.

- Прием **и промежуточное хранение данных:** Хранилище BLOB-объектов Azure в сочетании с Polybase для быстрой загрузки параллельных данных может использоваться для части процесса ETL/ELT, а не для реляционных таблиц.
- **Слой отчетов и киоски данных:** Характеристики производительности Azure синапсе Analytics могут устранить необходимость физического создания экземпляров агрегированных таблиц для целей отчетности или киосков данных. Их можно реализовать в качестве представлений в основном хранилище данных или на уровне виртуализации данных стороннего производителя. На базовом уровне процесс переноса данных с предысторией и, возможно, также может быть выполнен с помощью добавочных обновлений, как показано ниже.

![Современное хранилище данных](../../../_images/analytics/schema-migration-ddl.png)

Если можно использовать эти или аналогичные подходы, количество перемещаемых таблиц уменьшается, а некоторые процессы могут быть упрощены или исключены, что еще больше сокращает рабочую нагрузку миграции. Применимость этих подходов зависит от конкретного варианта использования, но общий принцип заключается в том, чтобы использовать функции и средства экосистемы Azure, где это возможно, чтобы сократить рабочую нагрузку миграции и создать экономичную целевую среду. Это также относится и к другим функциям, таким как резервное копирование и восстановление, Управление рабочими процессами и мониторинг.

Существуют также продукты и службы, предоставляемые партнерами Майкрософт для помощи в переносе хранилища данных, а в некоторых случаях Автоматизируйте части процесса. Если существующая система включает в себя сторонний продукт ETL, возможно, это уже поддерживает Azure синапсе Analytics в качестве целевой среды, а существующие рабочие процессы ETL можно перенаправить в новое целевое хранилище данных SQL Azure.

### <a name="data-marts-physical-or-virtual"></a>Киоски данных: физические или виртуальные

В устаревших средах хранилища данных рекомендуется создать несколько киосков данных, структурированных для обеспечения хорошей производительности для нерегламентированных запросов и отчетов по конкретному отделу или бизнес-функции в Организации. Таким образом, киоск данных обычно состоит из подмножества хранилища данных, содержащего статистические версии данных в форме, которая позволяет пользователям легко запрашивать эти данные с помощью удобных для пользователя средств запросов, таких как Tableau, Микростратеги или Microsoft Power BI. Эта форма обычно является многомерной моделью данных, и одним из способов использования киосков данных является предоставление данных в пригодной для использования форме, даже если базовая модель данных хранилища отличается (например, хранилище данных). Этот подход также известен как модель с тремя уровнями.

Отдельные киоски данных для отдельных подразделений в организации также можно использовать для реализации надежной режимы безопасности данных, разрешая пользователю доступ только к конкретным киоскам данных, относящимся к ним, и удалению, маскировке или анонимизирующие конфиденциальные данные.

Если эти киоски данных реализованы в виде физических таблиц, они требуют дополнительных ресурсов хранилища для их хранения, а также дополнительную обработку для регулярной сборки и обновления. Также подразумевается, что данные в киоске находятся в актуальном состоянии, как и последняя операция обновления, поэтому они могут не подойти для панелей мониторинга с очень энергонезависимыми данными.

С появлением относительно дешевых масштабируемых архитектур (MPP), таких как Azure синапсе Analytics и их характеристик производительности, может быть предоставлена возможность киоска данных без необходимости создания экземпляра киоска в виде набора физических таблиц. Это достигается за счет эффективного виртуализации киосков данных с помощью представлений SQL в основном хранилище данных или на уровне виртуализации с помощью таких функций, как представления в Azure синапсе Analytics или сторонних продуктов виртуализации, таких как Денодо. Такой подход упрощает или исключает потребность в дополнительных объемах хранилища и статистической обработке, а также сокращает общее число переносимых объектов базы данных.

Существует также еще одно потенциальное преимущество этого подхода. Реализуя логику агрегирования и объединения на уровне виртуализации и предоставляя внешние средства создания отчетов через виртуализированное представление, обработка, необходимая для создания этих представлений, передается в хранилище данных, что обычно является лучшим местом для выполнения таких операций, как объединение и агрегирование на больших объемах данных.

Основные драйверы для реализации физической или виртуальной киоска данных:

- Более гибкое изменение виртуального киоска данных проще, чем физические таблицы и связанные процессы ETL.
- Снижение совокупной стоимости владения из-за меньшего количества хранилищ данных и копий данных в виртуализованной реализации.
- Исключение заданий ETL для переноса и упрощения архитектуры хранилища данных в виртуализированной среде.
- Производительность. все исторические киоски данных стали более производительными, хотя продукты виртуализации теперь реализуют интеллектуальные методы кэширования для устранения этой проблемы.

Виртуализация данных также может использоваться для предоставления конечным пользователям единообразного представления данных во время выполнения проекта миграции.

### <a name="data-mapping"></a>Сопоставление данных

**Ограничения ключей и целостности в Azure синапсе Analytics:**

Ограничения первичного ключа и внешнего ключа в настоящее время не применяются в Azure синапсе Analytics, однако определение для `PRIMARY KEY` можно включить в `CREATE TABLE` инструкцию с `NOT ENFORCED` предложением. Это означает, что сторонние продукты отчетов могут использовать метаданные для таблицы, чтобы понять ключи в модели данных и, таким образом, создавать наиболее эффективные запросы.

**Поддержка типов данных в Azure синапсе Analytics:**

Некоторые устаревшие системы баз данных включают поддержку типов данных, которые в настоящее время не поддерживаются непосредственно в Azure синапсе Analytics. Однако эти типы данных обычно можно обрабатывать либо с помощью поддерживаемого типа данных для хранения данных, либо путем преобразования данных в поддерживаемый тип данных.

Ниже приведен алфавитный список поддерживаемых типов данных.

<!-- TODO: Review format of this list. Are the arguments necessary for this list? -->

<!-- docsTest:disable -->

- `bigint`
- `binary [ (n) ]`
- `bit`
- `char [ (n) ]`
- `date`
- `datetime`
- `datetime2 [ (n) ]`
- `datetimeoffset [ (n) ]`
- `decimal [ (precision [, scale ]) ]`
- `float [ (n) ]`
- `int`
- `money`
- `nchar [ (n) ]`
- `numeric [ (precision [ , scale ]) ]`
- `nvarchar [ (n | MAX) ]`
- `real [ (n) ]`
- `smalldatetime`
- `smallint`
- `smallmoney`
- `time [ (n) ]`
- `tinyint`
- `uniqueidentifier`
- `varbinary [ (n | MAX) ]`
- `varchar [ (n | MAX) ]`

<!-- docsTest:enable -->

В следующей таблице перечислены некоторые распространенные типы данных, которые в настоящее время не поддерживаются вместе с рекомендуемым подходом к хранению этих типов в Azure синапсе Analytics. (Для конкретных сред, таких как Teradata или Netezza, дополнительные сведения см. в соответствующих документах.)

| **Неподдерживаемые типы данных** | **Обходное решение**                                                      |
|-----------------------|-----------------------------------------------------------------|
| `geometry`              | `varbinary`                                                       |
| `geography`             | `varbinary`                                                       |
| `hierarchyid`           | `nvarchar(4000)`                                                  |
| `image`                 | `varbinary`                                                       |
| `text`                  | `varchar`                                                         |
| `ntext`                 | `nvarchar`                                                        |
| `sql_variant`           | Разделить столбец на несколько строго типизированных столбцов                |
| `table`                 | Преобразовать во временные таблицы                                     |
| `timestamp`             | Переработайте код для использования `datetime2` и `CURRENT_TIMESTAMP` функции |
| `xml`                   | `varchar`                                                         |
| Определяемый пользователем тип     | Преобразовать обратно в собственный тип данных, если это возможно              |

**Потенциальные проблемы с данными:**

В зависимости от исходной среды существуют некоторые проблемы, которые могут вызвать проблемы при переносе данных.

- Существуют небольшие различия в способе `NULL` обработки данных в разных продуктах баз данных, например, порядок сортировки и обработка пустых символьных строк.
- `DATE`, `TIME` , `INTERVAL` , `TIME ZONE` данные и связанные функции могут сильно отличаться от продукта к продукту.

Тщательно протестируйте их, чтобы обеспечить достижение требуемых результатов в целевой среде. В ходе миграции также могут выявляться ошибки или неверные результаты, которые в настоящее время являются частью существующей исходной системы. Процесс миграции — хорошая возможность исправить все аномалии. Рекомендации по определению столбцов в Azure синапсе Analytics в устаревших системах можно найти столбцы, заданные с неэффективными типами данных, например поле, определяющее, `VARCHAR(20)` когда фактические значения данных помещаются в `CHAR(5)` поле, или использовать `INTEGER` поля, если все значения будут помещаться в `SMALLINT` поле. Это может привести к неэффективному хранению и производительности запросов, особенно в больших таблицах фактов.

Для проверки существующих определений данных и рационализировать определений данных может быть хорошим временем миграции. Это можно автоматизировать с помощью SQL-запросов, чтобы найти максимальное числовое значение или максимальную длину символов в поле данных и сравнить его с типом данных. Некоторые средства просмотра и миграции данных сторонних разработчиков также включают эту функцию.

Как правило, рекомендуется максимально сокращать общую длину строки для таблицы (например, с помощью наименьшего типа данных для каждого столбца, как описано выше), так как это обеспечит лучшую производительность запросов. Программа Polybase, которая является рекомендуемым методом загрузки данных из внешних таблиц для Azure синапсе Analytics, поддерживает максимальный размер строки, равный 1 МБ. Для строк, превышающих 1 МБ в Polybase, нельзя использовать для загрузки этой таблицы, вместо нее следует использовать bcp.

Для наиболее эффективного выполнения объединения Определите столбцы, используемые на обеих сторонах объединения, как один и тот же тип данных. Если ключ таблицы измерения определен так, что `SMALLINT` соответствующие ссылочные столбцы в таблицах фактов, использующих это измерение, также должны быть определены как `SMALLINT` .

Старайтесь не определять поля символов с большим размером по умолчанию. Если максимальный размер данных в поле составляет 50 символов, используйте `VARCHAR(50)` . Точно так же не используется, `NVARCHAR` Если `VARCHAR` будет достаточно. `NVARCHAR`хранит данные в Юникоде, чтобы разрешить различные кодировки символов языка, в то время как `VARCHAR` сохраняет данные ASCII и занимает меньше пространства.

## <a name="design-recommendations-summary"></a>Сводка рекомендаций по проектированию

Не переносите ненужные объекты или процессы. Используйте встроенные функции и функции в целевой среде Azure, где это необходимо, чтобы уменьшить фактическое количество объектов и процессов для миграции. Используйте уровень виртуализации, чтобы уменьшить или исключить количество физических киосков данных для переноса и обработки в хранилище данных.

Автоматизируйте, где это возможно. Используйте метаданные из системных каталогов в исходной системе, чтобы создать DDL для целевой среды. Если возможно, также Автоматизируйте создание документации. Такие партнеры корпорации Майкрософт, как Вхерескапе, могут предоставлять специализированные средства и службы для помощи с этим.

Выполните необходимые изменения модели данных или оптимизацию сопоставления данных на целевой платформе. Эти изменения можно выполнять более эффективно в Azure синапсе Analytics. Такой подход снижает влияние на исходные системы, которые, возможно, уже работают, близко к полной емкости.

## <a name="performance-options"></a>Параметры производительности

В этом разделе описываются функции, доступные в Azure синапсе Analytics, которые можно использовать для повышения производительности конкретной модели данных.

### <a name="general-approach"></a>Общий подход

Для переносимой базы данных уже была применена Настройка производительности с использованием функций, доступных на этой платформе, например индексов, секционирования данных и, возможно, распределения данных. В рамках подготовки к миграции эти данные должны быть документированы, так как это может быть хорошим указанием оптимизации, которые можно применить в целевой среде Azure синапсе Analytics.

Например, наличие неуникального индекса в таблице может указывать, что поля, используемые в индексе, часто используются для фильтрации, группирования или объединения. В новой среде это по-прежнему будет иметь место, поэтому при выборе полей для индексирования следует иметь в виду следующее. Рекомендации по миграции для конкретных исходных платформ, таких как Teradata и Netezza, подробно описаны в отдельных документах.

Используйте производительность и масштабируемость целевой среды Azure синапсе Analytics, чтобы поэкспериментировать с различными параметрами производительности, такими как распределение данных, чтобы определить оптимальный выбор альтернативных подходов (например, репликация и распределение хэша для большой таблицы измерения). Это не значит, что данные должны быть перезагружены из внешних источников. Проще и быстро тестировать альтернативные подходы в Azure синапсе Analytics, создавая копии любой таблицы с различными вариантами секционирования или распределения с помощью `CREATE TABLE AS SELECT` инструкции.

Используйте средства мониторинга, предоставляемые средой Azure, чтобы понять, как выполняются запросы и могут возникнуть узкие места. Существуют также средства сторонних партнеров Майкрософт, которые предоставляют доступ к панелям мониторинга и автоматизированному управлению ресурсами и оповещениям.

Каждая операция SQL в Azure синапсе Analytics вместе с ресурсами, используемыми этим запросом (например, памятью или ЦП), входит в системные таблицы, и для упрощения доступа к этим данным предоставляются серии динамических административных представлений.

В следующих разделах объясняются ключевые параметры в хранилище данных Azure для настройки производительности запросов. В существующих средах будут содержаться сведения о потенциальной оптимизации в целевой среде.

### <a name="temporary-tables"></a>Временные таблицы

Azure синапсе Analytics поддерживает временные таблицы, которые видны только сеансу, в котором они были созданы, существуют в течение сеанса пользователя и автоматически удаляются в конце сеанса.

Чтобы создать временную таблицу, перед именем таблицы добавьте в префикс хэш-символ ( `#` ). Все стандартные параметры индексирования и распространения можно использовать с временными таблицами (см. ниже).

Временные таблицы имеют некоторые ограничения.

- Переименование таблицы не допускается.
- Представления и разделы во временных таблицах не допускаются.
- Невозможно изменить разрешения для временных таблиц.

Временные таблицы обычно используются в обработке ETL/ELT, где временные промежуточные результаты используются как часть процесса преобразования.

### <a name="table-distribution-options"></a>Параметры распространения таблицы

Azure синапсе Analytics — это система баз данных с массовой параллельной обработкой (MPP), которая обеспечивает производительность и масштабируемость путем параллельного выполнения на нескольких узлах обработки.

Идеальный сценарий обработки при выполнении SQL-запроса в среде с несколькими узлами заключается в балансировке рабочей нагрузки таким образом, чтобы все узлы имели одинаковый объем данных для обработки, в то время как одновременно свести к минимуму объем данных, которые должны быть перемещены между узлами для удовлетворения запроса.

В типичных аналитических запросах часто встречаются несколько соединений между несколькими таблицами (например, между таблицами фактов и таблицами измерений), а также агрегатами и, следовательно, может быть трудно добиться идеального сценария.

Одним из способов влияния на обработку запросов является использование параметров распространения в Azure синапсе Analytics для указания места хранения отдельных строк данных в каждой таблице. Например, если две большие таблицы часто соединяются с заданным столбцом данных `CUSTOMER_ID` , например путем распределения двух таблиц с использованием `CUSTOMER_ID` столбцов при каждом выполнении соединения, то данные из каждой стороны соединения будут уже содержаться в одном и том же узле обработки, что устраняет необходимость перемещения данных между узлами. Спецификация распределения для таблицы определена в `CREATE TABLE` инструкции.

Ниже приведены доступные варианты распространения и рекомендации по их использованию. При необходимости можно изменить распределение таблицы после начальной загрузки, повторно создав таблицу с новым распределением с помощью `CREATE TABLE AS SELECT` инструкции.

#### <a name="round-robin"></a>Циклический перебор

Это распределение таблиц является параметром по умолчанию и равномерно распределяет данные между узлами в системе. Этот метод хорошо подходит для быстрой загрузки данных и для данных, относительно небольшого объема, и не имеет очевидных кандидатов для хэширования, поэтому он часто используется для промежуточных таблиц как часть процесса ETL или ELT.

#### <a name="hashed"></a>Хэшируется

На основе алгоритма хэширования, применяемого к определяемому пользователем ключу (как `CUSTOMER_ID` в примере выше), система назначает строку хэш-контейнеру, который затем назначается определенному узлу. Все строки данных, распределенные по одному и тому же значению, будут заканчиваться на одном и том же узле обработки.

Этот метод полезен для больших таблиц, которые часто соединяются или объединяются по заданному ключу. Если возможно, другие большие таблицы, которые необходимо объединить, должны быть хэшированы по тому же ключу. Если существует несколько кандидатов для хэш-ключа, выберите наиболее часто соединяемый. Хэш-столбец не должен содержать значения NULL и обычно не является датой, так как многие запросы фильтруются по дате). Хэширование обычно более эффективно, если ключ для хэширования является целочисленным значением, а не `CHAR` или `VARCHAR` . Кроме того, не следует выбирать ключи с сильно отклоненным диапазоном значений, например небольшое количество ключевых значений, представляющих большой процент строк данных.

#### <a name="replicated"></a>Реплицированный

Если выбрать параметр реплицировать в качестве параметра распределения для таблицы, то полная копия этой таблицы будет реплицирована на каждый вычислительный узел для обработки запросов.

Этот подход удобен для относительно небольших таблиц (обычно менее 2 ГБ), которые относительно статичны и часто соединяются с большими таблицами через эквивалентное соединение. Эти таблицы часто представляют собой многомерные таблицы в схеме типа «звезда».

### <a name="indexing"></a>Индексация

Azure синапсе Analytics включает несколько вариантов индексирования данных в больших таблицах, чтобы сократить количество ресурсов и время, необходимое для получения записей.

- Кластеризованный индекс columnstore
- Кластеризованный индекс
- Некластеризованный индекс

Также существует неиндексированный параметр, вызываемый `HEAP` для таблиц, которые не будут использовать ни один из параметров индекса. Использование индексов — это компромисс между улучшением времени запроса и более длительным временем загрузки и объемом использования дискового пространства. Индексы часто ускоряют `SELECT` `UPDATE` операции, `DELETE` и `MERGE` в больших таблицах, влияющих на небольшой процент строк данных, а индексы позволяют избежать полных просмотров таблиц.

Индексы создаются автоматически, `UNIQUE` Если `PRIMARY KEY` для столбцов определены ограничения или.

#### <a name="clustered-columnstore-index"></a>Кластеризованный индекс columnstore

Это параметр индексирования по умолчанию в Azure синапсе Analytics, обеспечивающий наилучшее сжатие и производительность запросов для больших таблиц. Для небольших таблиц (менее 60 000 000 строк) эти индексы не являются эффективными, поэтому следует использовать параметр heap. Аналогично, если данные в таблице являются временными (возможно, часть процесса ETL/ELT) или временная таблица может быть более эффективной.

#### <a name="clustered-index"></a>Кластеризованный индекс

Если требуется регулярно получать одну строку или небольшое количество строк из большой таблицы на основе условия строгого фильтра, кластеризованный индекс может оказаться более эффективным, чем кластеризованный индекс columnstore. Для каждой таблицы допускается только один кластеризованный индекс. Репликация

#### <a name="non-clustered-index"></a>Некластеризованный индекс

Некластеризованные индексы похожи на кластеризованные индексы в том, что они могут ускорить получение отдельных строк или небольшое количество строк на основе условия фильтра. Внутренние некластеризованные индексы хранятся отдельно от данных, и для таблицы можно определить несколько некластеризованных индексов. Однако для каждого дополнительного индекса потребуется больше места для хранения данных и будет снижена пропускная способность при вставке или загрузке.

#### <a name="heap"></a>Куча

Таблицы кучи не имеют никаких издержек, связанных с созданием и обслуживанием индексов во время загрузки данных, и поэтому могут быть полезны для быстрой загрузки временных данных (например, в ходе процесса ETL). При чтении данных, которые следуют сразу, может также возникнуть преимущество кэширования в этом случае. Таблицы кучи также могут быть полезны для хранения таблиц с размером менее 60 000 000 строк, так как кластеризованные индексы columnstore неэффективны ниже этого размера.

### <a name="data-partitioning"></a>Секционирование данных

В хранилище данных предприятия таблицы фактов могут содержать много миллиардов строк и секционирования — это способ оптимизации обслуживания и выполнения запросов к этим таблицам путем разбиения их на отдельные части для уменьшения объема данных, обрабатываемых при выполнении запросов. Спецификация секционирования для таблицы определена в `CREATE TABLE` инструкции.

Для секционирования можно использовать только одно поле на таблицу, которое часто является полем даты, так как многие запросы фильтруются по датам или диапазонам дат. Можно изменить секционирование таблицы после начальной загрузки, если это необходимо, повторно создав таблицу с новым распределением с помощью `CREATE TABLE AS SELECT` инструкции.

#### <a name="partitioning-for-query-optimization"></a>Секционирование для оптимизации запросов

Если запросы к большой таблице фактов часто фильтруются по определенному столбцу данных, секционирование по этому столбцу может значительно сократить объем данных, которые необходимо обработать для выполнения запросов. Распространенным примером является использование поля даты для разбиения таблицы на более мелкие группы, каждая из которых содержит данные за один день. Если запрос содержит `WHERE` предложение, которое фильтрует по дате, необходимо получить доступ только к тем секциям, которые соответствуют фильтру дат.

#### <a name="partitioning-for-table-maintenance-optimization"></a>Секционирование для оптимизации обслуживания таблиц

Как правило, в средах хранилища данных поддерживается пошаговое окно подробных данных фактов, например, транзакций продаж в течение пяти лет. При секционировании на дату продажи удаление старых данных, находящихся за пределами окна, значительно повышает эффективность. Удаление самой старой секции производится быстрее и использует меньше ресурсов, чем удаление всех отдельных строк.

### <a name="statistics"></a>Статистика

Когда запрос отправляется в Azure синапсе Analytics, он сначала обрабатывается оптимизатором запросов, который определяет лучшие внутренние методы, используемые для эффективного выполнения запроса. Оптимизатор сравнивает различные планы выполнения запросов, доступные на основе алгоритма на основе стоимости, и точность оценки затрат зависит от доступной статистики. Поэтому рекомендуется обеспечить актуальность статистики.

Если этот параметр включен, в Azure синапсе Analytics `AUTO_CREATE_STATISTICS` будет активировано автоматическое обновление статистики. Статистику также можно создать или обновить вручную с помощью `CREATE STATISTICS` команды.

Обновление статистики при значительном изменении содержимого (например, в ежедневном обновлении). Это обновление можно встроить в процесс ETL.

Все таблицы в базе данных должны иметь статистические данные, собранные по крайней мере в одном столбце (чтобы гарантировать, что оптимизатору доступны базовые сведения, такие как число строк и размер таблицы). Другие столбцы, для которых должна быть собрана статистика, — это столбцы, указанные в `JOIN` `DISTINCT` обработке,, `ORDER BY` и `GROUP BY` .

### <a name="workload-management"></a>Управление рабочей нагрузкой

Azure синапсе Analytics включает в себя комплексные функции для управления использованием ресурсов в смешанных рабочих нагрузках. Создание классов ресурсов для различных типов рабочих нагрузок (таких как запросы и загрузка данных) помогает управлять рабочей нагрузкой путем установки ограничений на количество параллельно выполняемых запросов и для ресурсов, назначенных каждому запросу. Между требованиями к памяти и параллелизму существует зависимость.

- Небольшие классы ресурсов уменьшают максимальный объем памяти для каждого запроса, но обеспечивают больший параллелизм.
- Большие классы ресурсов увеличивают максимальный объем памяти для каждого запроса, но снижают уровень параллелизма.

### <a name="performance-recommendations"></a>Рекомендации по производительности

Используйте любые методы улучшения производительности (например, индексы, распределение данных) как признаки кандидатов для схожих мер в новой целевой среде, но для подтверждения их необходимости в Azure синапсе Analytics. `COLLECT STATISTICS`Выполните сборку действий в процессах ETL/ELT, чтобы обеспечить актуальность статистики, или включите автоматическое создание статистики.

Ознакомьтесь с параметрами настройки, доступными в Azure синапсе Analytics, и характеристиками производительности связанных служебных программ, например Polybase для быстрой загрузки данных с параллельной обработкой. Используйте эти параметры для создания эффективной сквозной реализации.

Используйте гибкость, масштабируемость и производительность среды Azure, чтобы реализовать любые изменения модели данных или параметры настройки производительности на месте, чтобы снизить влияние на существующие исходные системы.

Ознакомьтесь с динамическими административными представлениями, доступными в Azure синапсе Analytics, чтобы предоставить сведения об использовании ресурсов на уровне всей системы и подробные сведения о выполнении отдельных запросов.

Изучите классы ресурсов Azure и выделите их соответствующим образом, чтобы обеспечить эффективное управление смешанными рабочими нагрузками и параллелизмом.

Используйте уровень виртуализации в рамках среды Azure синапсе Analytics, чтобы защитить изменения в реализации хранилища от бизнес-пользователей и средств создания отчетов.

Изучите средства и службы миграции, предоставляемые сторонними поставщиками, например Attunity replicate для миграций Майкрософт, Вхерескапе и Datometry. Эти средства могут автоматизировать часть процесса миграции и сократить затраченное время и риск, связанные с проектом миграции.
